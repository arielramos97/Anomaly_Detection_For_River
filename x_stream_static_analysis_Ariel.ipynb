{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xStream (row streaming) vs static results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "from Chains import Chains"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gzip.open(\"data/telescope.gz\", \"r\")\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for i in data:\n",
    "  i = (i.decode('utf-8')).split(\",\")\n",
    "  i = [float(x) for x in i]\n",
    "  X.append(np.array(i[:-1]))\n",
    "  #X.append(i[:-1])\n",
    "  y.append(i[-1])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 100/100 [04:14<00:00,  2.55s/it]\n",
      "Scoring...: 100%|██████████| 100/100 [03:44<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xstream: AP = 0.3590784683191133 AUC = 0.7636916498432945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 100/100 [04:14<00:00,  2.54s/it]\n",
      "Scoring...: 100%|██████████| 100/100 [03:41<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xstream: AP = 0.36338391526192265 AUC = 0.7514101191944018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 100/100 [04:13<00:00,  2.54s/it]\n",
      "Scoring...: 100%|██████████| 100/100 [03:43<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xstream: AP = 0.3460506906656493 AUC = 0.7395799972236746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 100/100 [04:12<00:00,  2.53s/it]\n",
      "Scoring...: 100%|██████████| 100/100 [03:41<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xstream: AP = 0.36258231807558583 AUC = 0.7620152387520451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 100/100 [04:13<00:00,  2.54s/it]\n",
      "Scoring...:  86%|████████▌ | 86/100 [03:13<00:31,  2.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m model \u001b[39m=\u001b[39m Chains(k\u001b[39m=\u001b[39mk, nchains\u001b[39m=\u001b[39mn_chains, depth\u001b[39m=\u001b[39mdepth)\n\u001b[0;32m     25\u001b[0m model\u001b[39m.\u001b[39mfit(X_shuffled) \n\u001b[1;32m---> 26\u001b[0m anomalyscores \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mmodel\u001b[39m.\u001b[39;49mscore(X_shuffled)  \u001b[39m# unsupervised, as such, training does not make ground truth labels available to the models but only used for evaluation.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m ap \u001b[39m=\u001b[39m average_precision_score(y_shuffled, anomalyscores)\n\u001b[0;32m     28\u001b[0m auc \u001b[39m=\u001b[39m roc_auc_score(y_shuffled, anomalyscores)\n",
      "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Data_Science\\Chains.py:97\u001b[0m, in \u001b[0;36mChains.score\u001b[1;34m(self, X, adjusted)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(\u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnchains), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mScoring...\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     96\u001b[0m     chain \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchains[i]\n\u001b[1;32m---> 97\u001b[0m     scores \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39;49mscore(projected_X, adjusted)\n\u001b[0;32m     98\u001b[0m scores \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnchains)\n\u001b[0;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Data_Science\\Chains.py:69\u001b[0m, in \u001b[0;36mChain.score\u001b[1;34m(self, X, adjusted)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscore\u001b[39m(\u001b[39mself\u001b[39m, X, adjusted\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     67\u001b[0m     \u001b[39m# scale score logarithmically to avoid overflow:\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[39m#    score = min_d [ log2(bincount x 2^d) = log2(bincount) + d ]\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbincount(X)\n\u001b[0;32m     70\u001b[0m     depths \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([d \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdepth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)])\n\u001b[0;32m     71\u001b[0m     scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog2(\u001b[39m1.0\u001b[39m \u001b[39m+\u001b[39m scores) \u001b[39m+\u001b[39m depths \u001b[39m# add 1 to avoid log(0)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Data_Science\\Chains.py:58\u001b[0m, in \u001b[0;36mChain.bincount\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     56\u001b[0m cmsketch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcmsketches[depth]\n\u001b[0;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m i, prebin \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(prebins):\n\u001b[1;32m---> 58\u001b[0m     l \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(np\u001b[39m.\u001b[39;49mfloor(prebin)\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mint))\n\u001b[0;32m     59\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m l \u001b[39min\u001b[39;00m cmsketch:\n\u001b[0;32m     60\u001b[0m         scores[i,depth] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Replicate Static results shown in paper (Not row_streaming)\n",
    "\n",
    "k = 100 \n",
    "n_chains = 100 \n",
    "depth = 15\n",
    "\n",
    "aps = []\n",
    "aucs = []\n",
    "\n",
    "for i in range(2):\n",
    "    X_shuffled, y_shuffled = shuffle(X, y, random_state=i)\n",
    "    \n",
    "    model = Chains(k=k, nchains=n_chains, depth=depth)\n",
    "\n",
    "    model.fit(X_shuffled) \n",
    "    anomalyscores = -model.score(X_shuffled)  # unsupervised, as such, training does not make ground truth labels available to the models but only used for evaluation.\n",
    "    ap = average_precision_score(y_shuffled, anomalyscores)\n",
    "    auc = roc_auc_score(y_shuffled, anomalyscores)\n",
    "    print(\"xstream: AP =\", ap, \"AUC =\", auc)\n",
    "    aps.append(ap)\n",
    "    aucs.append(auc)\n",
    "\n",
    "print('Average ap over 10 runs: ', sum(aps)/len(aps))\n",
    "print('Average auc over 10 runs: ', sum(aucs)/len(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ap over 10 runs:  0.3577738480805678\n",
      "Average auc over 10 runs:  0.754174251253354\n"
     ]
    }
   ],
   "source": [
    "print('Average ap over 10 runs: ', sum(aps)/len(aps))\n",
    "print('Average auc over 10 runs: ', sum(aucs)/len(aucs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09134615d3c11d3d66d95b41ba5927bd89680aa8b55941e9aa91f4d36f92235d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
